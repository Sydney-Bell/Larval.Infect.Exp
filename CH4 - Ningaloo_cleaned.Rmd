---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Load necessary packages and functions

```{r}
library('ggplot2'); packageVersion('ggplot2') #version 3.5.0
library(dplyr)
library(tidyr)
library(stats)
library(nlme)
library(glmmTMB)
library(DHARMa)
library(MCMCglmm)
library(coda)
library(parallel)

###### pseudo R2 function for conditional and marginal R2 values
pseudoR2.MCMCglmm <- function(mod, data) {
  # Create model matrix using the MCMCglmm model and data objects
  dt <- model.matrix(summary(mod)$fixed.formula, data=data)
  
  # Set logical condition to identify "Intercept" column in model matrix
  cond <- grep("Intercept", colnames(dt))
  
  # If "Intercept" exists, then subset the remaining columns without dropping dimensions for a one-column matrix
  if (sum(cond) > 0) {
    dt <- dt[, -cond, drop = FALSE]
  }
  
  # Identify variable names making sure they match the output
  cols <- colnames(mod$Sol)
  
  # Subset mod$Sol to only columns matching those in model matrix
  cond <- is.element(cols, colnames(dt))
  sol <- mod$Sol[, cond, drop = FALSE]
  
  # Subset model matrix where colnames match colnames in mod$Sol
  cond <- is.element(colnames(dt), cols)
  dt <- dt[, cond, drop = FALSE]
  
  # Calculate the variance associated with the fixed effects
  betas <- colMeans(sol)
  xs <- t(dt) * betas
  bx <- colSums(xs)
  sigf <- var(bx)
  
  # Calculate the variance associated with the random effects
  mod.vcv <- data.frame(mod$VCV[, 1:(ncol(mod$VCV) - 1)])
  sigr <- sum(as.numeric(colMeans(mod.vcv)))
  
  # Calculate the variance associated with the residual effects
  sige <- mean(mod$VCV[, "units"])
  
  # Marginal R² (variance explained by fixed factors)
  r2m.i <- sigf / {sigf + sige + sigr}
  
  # Conditional R² (variance explained by the entire model)
  r2c.i <- {sigf + sigr} / {sigf + sige + sigr}
  
  r2 <- c(marginal_R2 = r2m.i, conditional_R2 = r2c.i, 
           variance_fixed = sigf, variance_random = sigr, 
           variance_residual = sige)
  
  return(r2)
}


```

Cell Density Boxplot

```{r}
setwd("C:/Users/jc980786/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment")
cells <- read.csv("C:/Users/jc980786/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/celldensity.csv", header = TRUE)
str(cells)

# Make Treatment a factor
cells$Treatment <- factor(cells$Treatment, levels = c("Ambient", "31", "35.5"))
treatment_colors <- c("Ambient" = "green", "31" = "orange", "35.5" = "red")

# Reshape the data so that all 3 cell counts are combined
cells_long <- cells %>%
  pivot_longer(cols = starts_with("No.Cells"), 
               names_to = "Measurement", 
               values_to = "CellDensity",
               values_drop_na = TRUE)

# Create the box plot
celldenboxplot = ggplot(cells_long, aes(x = Cross, y = CellDensity, fill = Treatment)) +
  geom_boxplot() +
  labs(title = "Box Plot of Cell Density by Cross and Treatment",
       x = "Cross",
       y = "Cell Density") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = treatment_colors)

ggsave("celldensityboxplot.jpg", plot = boxplot, width = 25, height = 15)

#Stats for Cell Density

# provided a very small p-value (< 2.2e-16), indicating strong evidence against the null hypothesis of normality
shapiro.test(cells_long$CellDensity)
#data is nonparametric

# Perform Kruskal-Wallis test
kw_result <- kruskal.test(CellDensity ~ Treatment, data = cells_long)

# Check test result
print(kw_result)

#Kruskal-Wallis rank sum test
#data:  CellDensity by Treatment
#Kruskal-Wallis chi-squared = 90.004, df = 2, p-value < 2.2e-16

#Based on this result, you can conclude that there is a statistically significant difference in cell density among the different treatments (Ambient, 31, and 35.5).

# Example of pairwise Wilcoxon rank-sum test (pairwise comparisons)
pairwise.wilcox.test(cells_long$CellDensity, cells_long$Treatment, p.adjust.method = "bonferroni")

#Ambient vs. 31: The p-value is approximately 1, indicating no significant difference in cell density between Ambient and 31 treatments.
#Ambient vs. 35.5: The adjusted p-value is < 2e-16, indicating a highly significant difference in cell density between Ambient and 35.5 treatments.
#31 vs. 35.5: The adjusted p-value is also < 2e-16, indicating a highly significant difference in cell density between 31 and 35.5 treatments.

```

Two-Way Repeated Measures ANOVA
2 predictors: Treatment and CellType

```{r}
# 1. Check assumptions 
########### TREATMENT #############
# Convert Treatment to a factor
cells_long$Treatment <- factor(cells_long$Treatment)
str(cells_long)

boxplot(cells_long$CellDensity ~ cells_long$Treatment)

#Shapiro-Wilk test (H0: data is normal):
shapiro.test(subset(cells_long, Treatment=='Ambient')$CellDensity)
shapiro.test(subset(cells_long, Treatment=='31')$CellDensity)
shapiro.test(subset(cells_long, Treatment=='35.5')$CellDensity)
# …. (do a test for each level of the categorical variable)
# NOT NORMAL p<0.005

# Bartlett’s test (H0: variances are homogenous):
bartlett.test(cells_long$CellDensity ~ cells_long$Treatment)
#Bartlett's K-squared = Inf, df = 2, p-value < 2.2e-16
# NOT HOMOGENOUS

########## CELLTYPE #############
# Convert CellType to a factor
cells_long$CellType <- factor(cells_long$CellType)
str(cells_long)

boxplot(cells_long$CellDensity ~ cells_long$CellType)

sample_sizes <- table(cells_long$CellType)
#Shapiro-Wilk test (H0: data is normal):
shapiro.test(subset(cells_long, CellType=='C')$CellDensity)
shapiro.test(subset(cells_long, CellType=='D')$CellDensity)
# …. (do a test for each level of the categorical variable)

# Bartlett’s test (H0: variances are homogenous):
bartlett.test(cells_long$CellDensity ~ cells_long$CellType)
# Bartlett's K-squared = 24.126, df = 1, p-value = 9.024e-07
# NOT HOMOGENOUS

# 2. Assumptions are not met: Try scale transformations

########### TREATMENT #############

boxplot(sqrt(cells_long$CellDensity) ~ cells_long$Treatment) # square root transformed because we have counts

#Shapiro-Wilk test (H0: data is normal):
shapiro.test(sqrt(subset(cells_long, Treatment=='Ambient')$CellDensity))
shapiro.test(sqrt(subset(cells_long, Treatment=='31')$CellDensity))
shapiro.test(sqrt(subset(cells_long, Treatment=='35.5')$CellDensity))
# …. (do a test for each level of the categorical variable)
# NOT NORMAL p<0.005

# Bartlett’s test (H0: variances are homogenous):
bartlett.test(sqrt(cells_long$CellDensity) ~ cells_long$Treatment)
#Bartlett's K-squared = Inf, df = 2, p-value < 2.2e-16
# NOT HOMOGENOUS

########## CELLTYPE #############

boxplot(sqrt(cells_long$CellDensity) ~ cells_long$CellType) # square root transformed because we have counts

sample_sizes <- table(cells_long$CellType)
#Shapiro-Wilk test (H0: data is normal):
shapiro.test(sqrt(subset(cells_long, CellType=='C')$CellDensity))
shapiro.test(sqrt(subset(cells_long, CellType=='D')$CellDensity))
# …. (do a test for each level of the categorical variable)

# Bartlett’s test (H0: variances are homogenous):
bartlett.test(sqrt(cells_long$CellDensity) ~ cells_long$CellType)
# Bartlett's K-squared = 4.5066, df = 1, p-value = 0.03377
# HOMOGENOUS

# 3. Do non-parametric test by rank-transforming the data
rDV<-rank(cells_long$CellDensity)

lme.rank<-lme(fixed = rDV ~ Treatment * CellType, random=~1|Cross, data = cells_long)
celldenanova <- anova (lme.rank)
#                       numDF       denDF      F-value       p-value
# (Intercept)             1         358        518.9960     <0.0001
# Treatment               2         358         64.6619     <0.0001
# CellType                1         358         1.8426      0.1755
# Treatment:CellType      2         358         5.1615      0.0062

plot(CellDensity ~ Treatment*CellType, data = cells_long)

# Treatment: F(2, 358) = 64.6619, p = <0.0001
# CellType: NOT sig
# Interaction: F(2, 358) = 5.1615, p = 0.0062

```

Analyze significant interaction Treatment*CellType

```{r}
interaction.plot(cells_long$CellType, cells_long$Treatment, cells_long$CellDensity, 
                 xlab="CellType", ylab="CellDensity", trace.label="Treatment")

# Example using pairwise comparisons
pairwise.t.test(cells_long$CellDensity, interaction(cells_long$Treatment, cells_long$CellType), p.adjust.method = "bonferroni")
#	Pairwise comparisons using t tests with pooled SD 

#data:  cells_long$CellDensity and interaction(cells_long$Treatment, cells_long$CellType) 

#          Ambient.C 31.C    35.5.C  Ambient.D 31.D   
#31.C      0.05188   -       -       -         -      
#35.5.C    0.00012   1.00000 -       -         -      
#Ambient.D 0.01986   1.00000 1.00000 -         -      
#31.D      1.00000   1.00000 0.03891 1.00000   -      
#35.5.D    0.00012   1.00000 1.00000 1.00000   0.03891

#P value adjustment method: bonferroni 
library(emmeans)
# Fit the linear mixed-effects model
lme.rank <- lme(fixed = rDV ~ Treatment * CellType, random = ~1|Cross, data = cells_long)

# Obtain the estimated marginal means
emm <- emmeans(lme.rank, ~ Treatment * CellType)

# Perform Tukey's post hoc test
tukey_result <- pairs(emm, adjust = "tukey")

# Print the results
print(tukey_result)

# Load necessary libraries
library(ggplot2)

# Create boxplot with facets by CellType and colors by Treatment
cells_long$Treatment <- factor(cells_long$Treatment, levels = c("Ambient", "31", "35.5"))


ggplot(cells_long, aes(x = Treatment, y = CellDensity, fill = Treatment)) +
  geom_boxplot() +
  facet_grid(. ~ CellType) +
  labs(title = "Boxplot of Cell Density by Treatment and Cell Type",
       x = "Treatment",
       y = "Cell Density",
       fill = "Treatment") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("Ambient" = "green","31" = "orange", "35.5" = "red"))

# Contrast for the difference in changes between CellTypes
contrast.emm <- contrast(emm, interaction = "pairwise", method = "revpairwise")
contrast.emm


```

Survival Analysis
Cox model: with Treatment and ReefMom

```{r}
setwd("C:/Users/jc980786/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment")

metadata = read.csv("C:/Users/jc980786/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/Metadata_NingSpawn2024_FINAL2.csv", header = TRUE)
str(metadata)

# Determine the class of the Factors (not the covariates):
class(metadata$Treatment)
class(metadata$SymbiontTreatment)
class(metadata$ReefMom)
#If any of the factors is not a “factor”, redefine it as a factor:
metadata$Treatment <- factor(metadata$Treatment)
metadata$SymbiontTreatment <- factor(metadata$SymbiontTreatment)
metadata$ReefMom <- factor(metadata$ReefMom)
attach (metadata)

# Create the Status column
# Zero = Alive
metadata$Status <- ifelse(metadata$`Alive, Dead, Sampled` == "Alive", 0, 1)
# Check for missing values in the columns used in the model
sum(is.na(metadata$Timepoint))
sum(is.na(metadata$Status))
sum(is.na(metadata$Treatment))
sum(is.na(metadata$SymbiontTreatment))
sum(is.na(metadata$ReefMom))

# Keep the entire metadata dataset, but filter out rows with NA in specific columns
metadata_clean <- metadata %>%
  filter(!is.na(Timepoint) & !is.na(Status) & !is.na(Treatment) & !is.na(SymbiontTreatment) & !is.na(ReefMom))

# Check the dimensions to ensure you retain all necessary columns
dim(metadata_clean)  # Check number of rows and columns

# Verify the changes
head(metadata)

#Install package survival
library(survival)
X<-cbind(metadata_clean$Treatment, metadata_clean$SymbiontTreatment, metadata_clean$ReefMom)# if you don’t have covariates, do not include them
# if observations are right censored:
cox<- coxph (Surv(Timepoint, Status)~ X, method='breslow', data = metadata_clean)
summary(cox)

#Call:
#coxph(formula = Surv(Timepoint, Status) ~ X, data = metadata, 
#    method = "breslow")

#  n= 2772, number of events= 1041 
#   (345 observations deleted due to missingness)

#                       coef exp(coef) se(coef)      z Pr(>|z|)    
#XTreatment         -0.24448   0.78311  0.03853 -6.346 2.22e-10 ***
#XSymbiontTreatment  0.04804   1.04921  0.06201  0.775  0.43848    
#XReefMom           -0.04209   0.95878  0.01553 -2.710  0.00673 ** 
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#                   exp(coef) exp(-coef) lower .95 upper .95
#XTreatment            0.7831     1.2770    0.7262    0.8445
#XSymbiontTreatment    1.0492     0.9531    0.9291    1.1848
#XReefMom              0.9588     1.0430    0.9300    0.9884

#Concordance= 0.546  (se = 0.01 )
#Likelihood ratio test= 48.83  on 3 df,   p=1e-10
#Wald test            = 48.21  on 3 df,   p=2e-10
#Score (logrank) test = 48.62  on 3 df,   p=2e-10

# Not all predictors are significant so use backward stepwise model selection to remove the most insignificant factor (symbiont treatment)

X2<-cbind(metadata_clean$Treatment, metadata_clean$ReefMom)# if you don’t have covariates, do not include them
# if observations are right censored:
cox2<- coxph (Surv(Timepoint, Status)~ X2, method='breslow', data = metadata_clean)
summary(cox2)

#Call:
#coxph(formula = Surv(Timepoint, Status) ~ X2, data = metadata, 
#    method = "breslow")

#  n= 2772, number of events= 1041 
#   (345 observations deleted due to missingness)

#                coef exp(coef) se(coef)      z Pr(>|z|)    
#X2Treatment -0.24448   0.78311  0.03853 -6.346 2.22e-10 ***
#X2ReefMom   -0.04209   0.95878  0.01553 -2.710  0.00673 ** 
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#            exp(coef) exp(-coef) lower .95 upper .95
#X2Treatment    0.7831      1.277    0.7262    0.8445
#X2ReefMom      0.9588      1.043    0.9300    0.9884

#Concordance= 0.546  (se = 0.01 )
#Likelihood ratio test= 48.23  on 2 df,   p=3e-11
#Wald test            = 47.61  on 2 df,   p=5e-11
#Score (logrank) test = 48.02  on 2 df,   p=4e-11

# Compare models
AIC(cox, cox2) #cox2 has the lowest AIC so we keep it

# Plot
# To plot the predicted probability of an event not occurring over time (for significant factors only) and use the model to make predictions

km <-survfit(Surv(Timepoint,Status)~ Treatment + ReefMom, data = metadata_clean) # do not include interactions
km
summary(km)

# Plot the survival curves
library(survival)
km$strata

# Plot the Kaplan-Meier curve
plot(km, 
     lwd = 2, 
     xlab = 'Time', 
     ylab = 'Probability of the Event not to occur', 
     lty = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21),
     col = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21),  # Dynamically adjust colors
     conf.int = FALSE)

#Use ggplot
install.packages("survminer")
library(survminer)
require("survival")
ggsurvplot(km)
# Create a combined label for legend
metadata_clean$combined_label <- with(metadata_clean, paste(Treatment, ReefMom, sep = "."))

# Now refit the survival object
km <- survfit(Surv(Timepoint, Status) ~ combined_label, data = metadata_clean)

# Generate unique labels for the legend based on combined_label
unique_combined_labels <- levels(as.factor(metadata_clean$combined_label))

# Plot the survival curves
ggsurv_all <- ggsurvplot(km, 
           data = metadata_clean, 
           conf.int = TRUE, 
           pval = TRUE, 
           risk.table = FALSE, 
           legend.title = "Treatment.ReefMom",
           legend.labs = unique_combined_labels,  # Now use combined labels
           title = "Kaplan-Meier Curve for Genet Survival", 
           risk.table.height = 2)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/survival_curves.png", plot = ggsurv_all$plot, width = 10, height = 8, dpi = 300)

ggsurv_all$plot +theme_bw()

### FACET
library(survival)

# Fit the Kaplan-Meier survival curve
km2 <- survfit(Surv(Timepoint, Status) ~ Treatment + ReefMom, data = metadata_clean)

ggsurv <- ggsurvplot(km2, conf.int = TRUE)

ggsurv$plot +theme_bw() + facet_wrap(~ Treatment)

library(survival)
library(survminer)
library(dplyr)

# Ensure Treatment is a factor with specified levels
metadata_clean$Treatment <- factor(metadata_clean$Treatment, levels = c("Ambient", "31", "35.5"))

# Create custom color names for each curve
custom_curve_names <- c("coral2", "orange", "darkkhaki", "aquamarine3", "darkred", "darkorchid", "blue","coral2", "orange", "darkkhaki", "aquamarine3", "darkred", "darkorchid", "blue","coral2", "orange", "darkkhaki", "aquamarine3", "darkred", "darkorchid", "blue"
)

levels(km2$strata)

# Create the survival plot with custom colors
ggsurv <- ggsurvplot(km2, conf.int = TRUE, 
                     palette = custom_curve_names,  # Custom color palette
                     legend.title = "ReefMom",
                     conf.int.alpha = 0.2)  # Set legend title

# Customize the plot
survival_curves_facet_ReefMom <- ggsurv$plot + 
    theme_bw() + 
    facet_wrap(~ Treatment)  # Faceting by Treatment

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/survival_curves_facet_ReefMom.png", plot = survival_curves_facet_ReefMom, width = 10, height = 5, dpi = 300)

#Bonferroni post-hoc test
# Perform pairwise comparisons of survival curves
pairs <- pairwise_survdiff(Surv(Timepoint, Status) ~ Treatment + ReefMom, 
                  data = metadata_clean,
                  p.adjust.method = "bonferroni")

pairs

# Symbolic number coding
symnum(pairs$p.value, cutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 1),
   symbols = c("****", "***", "**", "*", "+", " "),
   abbr.colnames = FALSE, na = "")


#########
# Interactions with SymbiontTreatment are significant
########
# Fit Cox proportional hazards model with interactions
cox.int <- coxph(Surv(Timepoint, Status) ~ Treatment * SymbiontTreatment * ReefMom, 
             method = 'breslow', data = metadata_clean)

# Display the summary of the model
summary(cox.int)
cox.zph(cox.int) # use this function to confirm p-values from interactions

#########
# Plot for visual
########
km.symb <- survfit(Surv(Timepoint, Status) ~ Treatment + ReefMom + SymbiontTreatment, data = metadata_clean)
summary(km.symb)

# Create custom color names for each curve
custom_curve_names2 <- c("coral2","coral2", "orange","orange","darkkhaki","darkkhaki","aquamarine3","aquamarine3","darkred","darkred","darkorchid","darkorchid","blue","blue","coral2","coral2", "orange","orange","darkkhaki","darkkhaki","aquamarine3","aquamarine3","darkred","darkred","darkorchid","darkorchid","blue","blue","coral2","coral2", "orange","orange","darkkhaki","darkkhaki","aquamarine3","aquamarine3","darkred","darkred","darkorchid","darkorchid","blue","blue")
                        
# Create the survival plot with custom colors
ggsurv <- ggsurvplot(km.symb, conf.int = TRUE, 
                     palette = custom_curve_names2,  # Custom color palette
                     legend.title = "ReefMom",
                     conf.int.alpha = 0.2)  # Set legend title

# Customize the plot
survival_curves_facet_Symb <- ggsurv$plot + 
    theme_bw() + 
    facet_wrap(~ Treatment + SymbiontTreatment)  # Faceting by Treatment and SymbiontTreatment

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/survival_curves_facet_Symb.png", plot = survival_curves_facet_Symb, width = 20, height = 5, dpi = 300)

#########################
# Extract survival probabilities at a specific time, e.g., time = 22
surv_summary_symb <- summary(km.symb, times = 22)

# Print the survival probability
print(surv_summary_symb$surv)

pairs_symb <- pairwise_survdiff(Surv(Timepoint, Status) ~ Treatment + ReefMom + SymbiontTreatment, 
                  data = metadata_clean,
                  p.adjust.method = "bonferroni")

pairs_symb


```

Survival Analysis
Cox model: with Treatment and Cross_2 (source reef)

```{r}
# Determine the class of the Factors (not the covariates):
class(metadata_clean$Cross_2)
#If any of the factors is not a “factor”, redefine it as a factor:
metadata_clean$Cross_2 <- factor(metadata_clean$Cross_2)
# Check for missing values in the columns used in the model
sum(is.na(metadata_clean$Cross_2))

#Install package survival
library(survival)
X3<-cbind(metadata_clean$Treatment, metadata_clean$Cross_2)# if you don’t have covariates, do not include them
# if observations are right censored:
cox3 <- coxph (Surv(Timepoint, Status)~ X3, method='breslow', data = metadata_clean)
summary(cox)

# Plot
# To plot the predicted probability of an event not occurring over time (for significant factors only) and use the model to make predictions

km3 <-survfit(Surv(Timepoint,Status)~ Treatment + Cross_2, data = metadata_clean) # do not include interactions
km3
summary(km3)

# Plot the survival curves
library(survival)
km3$strata

# Plot the Kaplan-Meier curve
plot(km3, 
     lwd = 2, 
     xlab = 'Time', 
     ylab = 'Probability of the Event not to occur', 
     lty = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21),
     col = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21),  # Dynamically adjust colors
     conf.int = FALSE)

#Use ggplot
install.packages("survminer")
library(survminer)
require("survival")
ggsurvplot(km3)
# Create a combined label for legend
metadata_clean$combined_label2 <- with(metadata_clean, paste(Treatment, Cross_2, sep = "."))

# Now refit the survival object
km4 <- survfit(Surv(Timepoint, Status) ~ combined_label2, data = metadata_clean)

# Generate unique labels for the legend based on combined_label
unique_combined_labels <- levels(as.factor(metadata_clean$combined_label2))

# Plot the survival curves
ggsurv_all <- ggsurvplot(km4, 
           data = metadata_clean, 
           conf.int = TRUE, 
           pval = TRUE, 
           risk.table = FALSE, 
           legend.title = "Treatment.Cross_2",
           legend.labs = unique_combined_labels,  # Now use combined labels
           title = "Kaplan-Meier Curve for Genet Survival", 
           risk.table.height = 2)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/survival_curves.png", plot = ggsurv_all$plot, width = 10, height = 8, dpi = 300)

ggsurv_all$plot +theme_bw()

### FACET
library(survival)

# Fit the Kaplan-Meier survival curve
km5 <- survfit(Surv(Timepoint, Status) ~ Treatment + Cross_2, data = metadata_clean)

summary(km5)

ggsurv <- ggsurvplot(km5, conf.int = TRUE)

ggsurv$plot +theme_bw() + facet_wrap(~ Treatment)

# Ensure Treatment is a factor with specified levels
metadata_clean$Treatment <- factor(metadata_clean$Treatment, levels = c("Ambient", "31", "35.5"))

# Create custom color names for each curve
custom_curve_names2 <- c("aquamarine3", "orange", "aquamarine3", "orange", "aquamarine3", "orange")

levels(km5$strata)

# Create the survival plot with custom colors
ggsurv <- ggsurvplot(km5, conf.int = TRUE, 
                     palette = custom_curve_names2,  # Custom color palette
                     legend.title = "Source Reef",
                     conf.int.alpha = 0.2)  # Set legend title

# Customize the plot
final_plot <- ggsurv$plot + 
              theme_bw() + 
              facet_wrap(~ Treatment)  # Faceting by Treatment

# Save the plot using ggsave
ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/survival_curves_facet_SourceReef.png", plot = final_plot, width = 10, height = 5, dpi = 300)

#Bonferroni post-hoc test
# Perform pairwise comparisons of survival curves
pair <- pairwise_survdiff(Surv(Timepoint, Status) ~ Treatment + Cross_2, 
                  data = metadata_clean,
                  p.adjust.method = "bonferroni")

pair

# Symbolic number coding
symnum(pair$p.value, cutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 0.1, 1),
   symbols = c("****", "***", "**", "*", "+", " "),
   abbr.colnames = FALSE, na = "")

# Extract survival probabilities at a specific time, e.g., time = 22
# You can do this using the 'summary()' function with the 'time' argument
surv_summary <- summary(km5, times = 22)

# Print the survival probability at time 50
print(surv_summary$surv)  # This gives the survival probabilities

#at day 22:
# ambient BxB = 0.4891414 +- 0.0836
# ambient TxT = 0.8182818 +- 0.0693
# 31 BxB = 0.1330052 +- 0.0438
# 31 TxT = 0.1398107 +- 0.0406
# 35.5 = 0.0000000 and 0.0000000


```

Survival Analysis
Just Treatment as a variable

```{r}
# Fit the Kaplan-Meier survival curve
km6 <- survfit(Surv(Timepoint, Status) ~ Treatment, data = metadata_clean)

summary(km6)

#Bonferroni post-hoc test
# Perform pairwise comparisons of survival curves
pair2 <- pairwise_survdiff(Surv(Timepoint, Status) ~ Treatment, 
                  data = metadata_clean,
                  p.adjust.method = "bonferroni")

pair2
```

Load in Ningaloo metadata and restructure

```{r}
#install.packages("MCMCglmm")
library(MCMCglmm)
#install.packages("lsmeans")
library(lsmeans)

totaldf = read.csv("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/Metadata_NingSpawn2024_FINAL2.csv", header = TRUE)
str(totaldf)

library(tidyr)

# Convert No.Cells1 to numeric
totaldf$No.Cells1 <- as.numeric(totaldf$No.Cells1)

# Reshape the data to long format so all of the cell densities are in one column
totaldf_long <- totaldf %>%
  pivot_longer(cols = c(No.Cells1, No.Cells2, No.Cells3), 
               names_to = "Cell_Measurement", 
               values_to = "Cell_Density")

# Check the structure of the reshaped data
str(totaldf_long)

# Replace empty strings with NA
totaldf_long$Cell_Density[totaldf_long$Cell_Density == ""] <- NA

# Convert the Cell_Density column to numeric 
totaldf_long$Cell_Density <- as.numeric(totaldf_long$Cell_Density)

# Check for missing values in each of the predictor columns
sum(is.na(totaldf_long$SymbiontTreatment))
sum(is.na(totaldf_long$Family))
sum(is.na(totaldf_long$Treatment))
sum(is.na(totaldf_long$Timepoint))  

# Keep rows up to 8316. After that they are just blank rows that got imported.
totaldf_long_subset <- totaldf_long[1:8316, ]

# Check the structure of the subset data frame
str(totaldf_long_subset)

totaldf_long_clean <- totaldf_long_subset %>%
  filter(!is.na(SymbiontTreatment) & !is.na(Family) & !is.na(Treatment) & !is.na(Timepoint))

# df is the main dataframe we'll be using
df <- totaldf_long_clean
```

Survival with binomial GLMM (Family) --> glmmTMB --> frequentist method

```{r}
#Check variables in dataset
str(df)
class(df$SymbiontTreatment) #iv
class(df$Family) #iv
class(df$Temp) #iv
class(df$Timepoint) #dv
class(df$Replicate) #dv

#Change categorical variables to factors
df$SymbiontTreatment<-factor(df$SymbiontTreatment)
df$Family<-factor(df$Family)
df$Temp<-factor(df$Temp)
df$Timepoint<-factor(df$Timepoint)
df$Replicate<-factor(df$Replicate)

# Check the levels of your categorical variables
levels(df$SymbiontTreatment)
levels(df$Family)
levels(df$Temp)
levels(df$Timepoint)
levels(df$Replicate)

#We want Temp as T1, T2, T3 for creating a unique tube ID later on. This line of code says that when Treatment = Ambient, Temp will = T1
df <- df %>%
  mutate(Temp = case_when(
    Treatment == "Ambient" ~ "T1",
    Treatment == "31" ~ "T2",
    Treatment == "35.5" ~ "T3",
    TRUE ~ as.character(Temp)  # Keep other values unchanged
  ))

#Convert Percent_Survival_atend from percentage (0-100) to decimal (0-1) for a binomial model
df_Surv <- df %>%
  mutate(Percent_Survival_atend = Percent_Survival_atend / 100)
df_Surv <- df_Surv %>%
  mutate(Dead_Larvae = No.LarvaeInExpected - No.LarvaeInObserved)  # Calculate the number of dead larvae for the model weights

# Check for missing values or non-integer counts
summary(df_Surv$No.LarvaeInObserved)
summary(df_Surv$Dead_Larvae)

# Ensure both columns are integers
df_Surv <- df_Surv %>%
  filter(!is.na(No.LarvaeInObserved) & !is.na(Dead_Larvae))  # Remove rows with NA values
# Remove rows where Dead_Larvae is negative
df_Surv <- df_Surv %>%
  filter(Dead_Larvae >= 0)

#Fit the most complex model
#weights will be the number of larvae expected in each vial (No.LarvaeInExpected)
mod.1 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Family * Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)

#Start with the most complex (‘full’) model, then drop IV terms one at a time. Compare the AIC scores and select the model with the lowest score.
mod.2 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Family * Temp + 
                   (1|Timepoint),
                 family = binomial, 
                 data = df_Surv)
mod.3 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Family * Temp + 
                 (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.4 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ Family * Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.5 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.6 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Family + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.7 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment + Family + Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)

#Select the best model (lowest AIC)
AIC(mod.1, mod.2, mod.3, mod.4, mod.5, mod.6, mod.7)
#mod.1 the fullest model is the best

#Validate the model
summary(mod.1)
install.packages("DHARMa")
library(DHARMa)

#The assumptions of linearity and homogeneity of variance for a GLMM are based upon the residuals, so we must extract them and then perform validation
simulationOutput <- simulateResiduals(mod.1, n = 1000)
plot(simulationOutput)
#The Q-Q plot visually shows if the points fall along a straight line, indicating that the data follows the theoretical distribution reasonably well.

#Levene Test for homogenity of variance significant for all variables
plotResiduals(simulationOutput, df_Surv$SymbiontTreatment)
plotResiduals(simulationOutput, df_Surv$Family)
plotResiduals(simulationOutput, df_Surv$Temp)

#Calculate R^2
install.packages("performance")
library(performance)
r2(mod.1)
#Conditional R2: 0.969
#Marginal R2: 0.502
#The conditional R2 is the variation in the DV explained by the fixed and random factors. The marginal R2 is the variation in the DV explained by the fixed factors alone.

#Post hoc analysis
#We can perform pairwise tests of the categorical IV(s) or interactions in our fitted model using the estimated marginal means.
library(emmeans) #package which extracts the estimated marginal means from a model for post hoc analysis of significant factors

#Interactions: SYmbiontTreatment
emm.mod <- emmeans(mod.1, ~ SymbiontTreatment | Family | Temp)
contrast(emm.mod)
pairs(emm.mod)
plot(emm.mod)
library(ggplot2)
emmip(mod.1, ~ SymbiontTreatment | Family | Temp, "response")+
geom_jitter(aes(x = SymbiontTreatment, y = Percent_Survival_atend, colour = SymbiontTreatment), data = df_Surv)

#Create heat map
emm_df <- as.data.frame(emm.mod)
library(ggplot2)
str(emm_df)

heatmap_plot <- ggplot(emm_df, aes(x = SymbiontTreatment, y = interaction(Family, Temp), fill = emmean)) +
  geom_tile(color = "white") +  # Creates the tiles
  scale_fill_gradient(low = "white", high = "red") +  # Change colors as needed
  labs(title = "Estimated Marginal Means Heatmap",
       x = "Symbiont Treatment",
       y = "Family and Temperature",
       fill = "EMM") +
  theme_minimal()

# Print the heatmap
print(heatmap_plot)

#Interactions: Temp
#The order of the independent variables matters so we will start with Temp (everything else is nested within Temp)
emm.mod1 <- emmeans(mod.1, ~ Temp | Family | SymbiontTreatment, type = "link")
# Convert emms object to data frame
emms_log_odds_df <- as.data.frame(emm.mod1)
# Calculate odds from log-odds by exponentiating the log-odds
emms_log_odds_df$odds <- exp(emms_log_odds_df$emmean)

# Select a baseline group's odds (e.g., the first row)
baseline_odds <- emms_log_odds_df$odds[1]

# Calculate fold change in odds for each group relative to baseline
emms_log_odds_df$fold_change_odds <- emms_log_odds_df$odds / baseline_odds

contrast(emm.mod1)
pairs(emm.mod1)
plot(emm.mod1)
library(ggplot2)
emmip(mod.1, ~ Temp | Family | SymbiontTreatment, "response")+
geom_jitter(aes(x = Temp, y = Percent_Survival_atend, colour = Temp), data = df_Surv)

#Create heat map
emm_df1 <- as.data.frame(emm.mod1)
library(ggplot2)
str(emm_df1)

# Create the heatmap
heatmap_plot <- ggplot(emm_df1, aes(x = Temp, y = interaction(Family, SymbiontTreatment), fill = emmean)) +
  geom_tile(color = "white") +  # Creates the tiles
  scale_fill_gradient(low = "white", high = "red") +  # Change colors as needed
  labs(title = "Estimated Marginal Means Heatmap",
       x = "Temperature",
       y = "Family and Symbiont Treatment",
       fill = "EMM") +
  theme_minimal()

# Print the heatmap
print(heatmap_plot)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_survival.png", plot = heatmap_plot, width = 10, height = 8, dpi = 300)

# Calculate log fold change in odds (log odds ratio)
baseline_log_odds <- emms_log_odds_df$emmean[1]
emms_log_odds_df$log_fold_change_odds <- emms_log_odds_df$emmean - baseline_log_odds

# Plot log fold change in odds (log odds ratio)
# Reorder the Family factor
emms_log_odds_df$Family <- factor(emms_log_odds_df$Family, levels = c("F1", "F2", "F3", "F4", "F6", "F7", "F10"))


heatmap_plot_density2 <- ggplot(emms_log_odds_df, aes(x = Family, y = SymbiontTreatment, fill = log_fold_change_odds)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 1, 
                       name = "Fold Change") +  # Set the midpoint to 1 (neutral fold change)
  facet_wrap(~ Temp) +  # Facet each Family in separate panels
  theme_minimal() +
  labs(title = "Heatmap of Log Fold Change in Larvae Survival by Family",
       x = "Tank Temperature",
       y = "Symbiont Treatment")

# Print the heatmap
print(heatmap_plot_density2)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_survival_log.png", plot = heatmap_plot_density2, width = 10, height = 8, dpi = 300)

library(piecewiseSEM)

###########
# Calculate R² values (marginal and conditional) for each variable
###########

#full model
r2_values <- rsquared(mod.1)
# Print the results
print(r2_values)

#Symbiont Treatment
mod.1.Symb <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment + 
                    (1|Timepoint) + (1|Replicate),
                  family = binomial, 
                  data = df_Surv)

r2_values.Symb <- rsquared(mod.1.Symb)
# Print the results
print(r2_values.Symb)
#Percent variance explained
r2_difference.Symb <- r2_values$Conditional - r2_values.Symb$Conditional
#Print results
print(r2_difference.Symb)
# Calculate percentage of variance explained
percent_explained.Symb <- (r2_difference.Symb / r2_values$Conditional) * 100

#Family
mod.1.Family <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ Family + 
                    (1|Timepoint) + (1|Replicate),
                  family = binomial, 
                  data = df_Surv)

r2_values.Family <- rsquared(mod.1.Family)

# Print the results
print(r2_values.Family)
#Percent variance explained
r2_difference.Family <- r2_values$Conditional - r2_values.Family$Conditional
#Print results
print(r2_difference.Family)
# Calculate percentage of variance explained
percent_explained.Family <- (r2_difference.Family / r2_values$Conditional) * 100

#Temp
mod.1.Temp <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ Temp + 
                    (1|Timepoint) + (1|Replicate),
                  family = binomial, 
                  data = df_Surv)

r2_values.Temp <- rsquared(mod.1.Temp)

# Print the results
print(r2_values.Temp)
#Percent variance explained
r2_difference.Temp <- r2_values$Conditional - r2_values.Temp$Conditional
#Print results
print(r2_difference.Temp)
# Calculate percentage of variance explained
percent_explained <- (r2_difference.Temp / r2_values$Conditional) * 100

```

Survival with binomial GLMM (Source Reef) --> glmmTMB

```{r}
#Check variables in dataset
str(df_Surv)
class(df_Surv$SymbiontTreatment) #iv
class(df_Surv$Cross_2) #iv
class(df_Surv$Temp) #iv
class(df_Surv$Timepoint) #dv
class(df_Surv$Replicate) #dv

#Change categorical variables to factors
df_Surv$SymbiontTreatment<-factor(df_Surv$SymbiontTreatment)
df_Surv$Cross_2<-factor(df_Surv$Cross_2)
df_Surv$Temp<-factor(df_Surv$Temp)
df_Surv$Timepoint<-factor(df_Surv$Timepoint)
df_Surv$Replicate<-factor(df_Surv$Replicate)

# Check the levels of your categorical variables
levels(df_Surv$SymbiontTreatment)
levels(df_Surv$Cross_2)
levels(df_Surv$Temp)
levels(df_Surv$Timepoint)
levels(df_Surv$Replicate)

#Fit the most complex model
#weights will be the number of larvae expected in each vial (No.LarvaeInExpected)
mod.8 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Cross_2 * Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)

#Start with the most complex (‘full’) model, then drop IV terms one at a time. Compare the AIC scores and select the model with the lowest score.
mod.9 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Cross_2 * Temp + 
                   (1|Timepoint),
                 family = binomial, 
                 data = df_Surv)
mod.10 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Cross_2 * Temp + 
                 (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.11 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ Cross_2 * Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.12 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.13 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment * Cross_2 + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)
mod.14 <- glmmTMB(cbind(No.LarvaeInObserved, Dead_Larvae) ~ SymbiontTreatment + Cross_2 + Temp + 
                   (1|Timepoint) + (1|Replicate),
                 family = binomial, 
                 data = df_Surv)

#Select the best model (lowest AIC)
AIC(mod.10, mod.12, mod.13, mod.8, mod.9, mod.14)
#mod.8 the fullest model is the best

#Validate the model
summary(mod.8)

#The assumptions of linearity and homogeneity of variance for a GLMM are based upon the residuals, so we must extract them and then perform validation
simulationOutput2 <- simulateResiduals(mod.8, n = 1000)
plot(simulationOutput2)
#The Q-Q plot visually shows if the points fall along a straight line, indicating that the data follows the theoretical distribution reasonably well.

#Levene Test for homogenity of variance significant for all variables
plotResiduals(simulationOutput2, df_Surv$SymbiontTreatment)
plotResiduals(simulationOutput2, df_Surv$Cross_2)
plotResiduals(simulationOutput2, df_Surv$Temp)

#Calculate R^2
install.packages("performance")
library(performance)
r2(mod.8)
#Conditional R2: 0.960
#Marginal R2: 0.447
#The conditional R2 is the variation in the DV explained by the fixed and random factors. The marginal R2 is the variation in the DV explained by the fixed factors alone.

#Post hoc analysis
#We can perform pairwise tests of the categorical IV(s) or interactions in our fitted model using the estimated marginal means.
library(emmeans) #package which extracts the estimated marginal means from a model for post hoc analysis of significant factors

#Interactions: SYmbiontTreatment
emm.mod2 <- emmeans(mod.8, ~ SymbiontTreatment | Cross_2 | Temp)
contrast(emm.mod2)
pairs(emm.mod2)
plot(emm.mod2)
emmip(mod.8, ~ SymbiontTreatment | Cross_2 | Temp, "response")+
geom_jitter(aes(x = SymbiontTreatment, y = Percent_Survival_atend, colour = SymbiontTreatment), data = df_Surv)

#Create heat map
emm_df <- as.data.frame(emm.mod)
str(emm_df)
heatmap_plot <- ggplot(emm_df, aes(x = SymbiontTreatment, y = interaction(Cross_2, Temp), fill = emmean)) +
  geom_tile(color = "white") +  # Creates the tiles
  scale_fill_gradient(low = "white", high = "blue") +  # Change colors as needed
  labs(title = "Estimated Marginal Means Heatmap",
       x = "Symbiont Treatment",
       y = "Family and Temperature",
       fill = "EMM") +
  theme_minimal()
# Print the heatmap
print(heatmap_plot)

#Interactions: Temp
emm.mod3 <- emmeans(mod.8, ~ Temp | Cross_2 | SymbiontTreatment)
contrast(emm.mod3)
pairs(emm.mod3)
plot(emm.mod3)
emmip(mod.8, ~ Temp | Cross_2 | SymbiontTreatment, "response")+
geom_jitter(aes(x = Temp, y = Percent_Survival_atend, colour = Temp), data = df_Surv)

#Create heat map
emm_df3 <- as.data.frame(emm.mod3)
str(emm_df3)
heatmap_plot_sourcereef <- ggplot(emm_df3, aes(x = Temp, y = interaction(Cross_2, SymbiontTreatment), fill = emmean)) +
  geom_tile(color = "white") +  # Creates the tiles
  scale_fill_gradient(low = "white", high = "blue") +  # Change colors as needed
  labs(title = "Estimated Marginal Means Heatmap",
       x = "Temperature",
       y = "Family and Symbiont Treatment",
       fill = "EMM") +
  theme_minimal()+
  facet_wrap(~ Cross_2, ncol = 1) 
# Print the heatmap
print(heatmap_plot_sourcereef)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_sourcereef_survival.png", plot = heatmap_plot_sourcereef, width = 10, height = 8, dpi = 300)

```

Density with GLMM --> MCMCglmm 
Fold change in cell density

```{r}
#fixed effects: symbiont identity, family cross, temperature treatment
#random effects: replicate, timepoint

# Create Cellinitial and Cellfinal columns
df_with_extremes <- df_with_extremes %>%
  filter(!is.na(Cell_Density))

df_with_extremes <- df_with_extremes %>%
  group_by(UniqueID) %>%
  arrange(Timepoint) %>%  # Ensure the dataframe is arranged by Timepoint
  mutate(
    Cellinitial = first(Cell_Density),  # First recorded value of cell density for each UniqueID
    Cellfinal = last(Cell_Density)     # Last recorded value of cell density for each UniqueID
  ) %>%
  ungroup()

# Calculate percent change, adding epsilon to initial values to avoid division by zero
epsilon <- 1e-8  # Add a small value to avoid division by zero
df_with_extremes$PercChangeCells <- ((df_with_extremes$Cellfinal - df_with_extremes$Cellinitial) / 
                                    (df_with_extremes$Cellinitial + epsilon)) * 100

# Define the priors
prior <- list(
  R = list(V = 1, nu = 0.002),  # Prior for residual variance
  G = list(
    G1 = list(V = 1, nu = 5),  # Prior for random effect Replicate
    G2 = list(V = 1, nu = 5)   # Prior for random effect Timepoint
  )
)

# Fit the model
model2 <- MCMCglmm(PercChangeCells ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate + Timepoint, 
                  data = df_with_extremes, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval

#Gelman-Rubin criterion: objective test to determine whether the obtained samples are good
set.seed(1)
m2 <- mclapply(1:4, function(i) {
  MCMCglmm(PercChangeCells ~ SymbiontTreatment * Family *
             Treatment, 
             random = ~ Replicate + Timepoint, 
             data = df_with_extremes, 
             family = "gaussian",  # Use gaussian for continuous proportions
             prior = prior,
             nitt = 50000,    # Number of MCMC iterations
             burnin = 10000,  # Burn-in period
             thin = 20)
})

m2 <- lapply(m2, function(m) m$Sol)
m2 <- do.call(mcmc.list, m2)

par(mfrow=c(4,2), mar=c(2,2,1,2))
gelman.plot(m2, auto.layout=F)
gelman.diag(m2)
#close to 1 so we can continue

#plot of the posterior means along with 95% credible intervals
plot.estimates2 <- function(model2) {
  # Ensure you have the correct summary
  model_summary2 <- summary(model2)
  
  # Extract and filter the relevant parts of the summary
  params2 <- rownames(model_summary2$solutions)
  relevant_params2 <- params2[grep("^(Intercept|SymbiontTreatment|Family|Treatment)", params2)]
  
  # Extract statistics and quantiles
  statistics2 <- model_summary2$solutions[relevant_params2, c("post.mean", "l-95% CI", "u-95% CI")]
  
  # Prepare data for plotting
  stats_df2 <- data.frame(
    parameter = rownames(statistics2),
    mean = statistics2[, "post.mean"],
    lower = statistics2[, "l-95% CI"],
    upper = statistics2[, "u-95% CI"]
  )
  
  # Plot the results
  library(ggplot2)
  ggplot(stats_df2, aes(x = mean, y = parameter)) +
    geom_point(size = 3) +
    geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    labs(title = "Posterior Means and 95% Credible Intervals",
         x = "Posterior Mean",
         y = "Parameter") +
    theme_minimal()
}

#### Check Assumptions ####
# Check trace plots to see if the chains are mixing and if there is convergence
#Check density plots to ensure the posterior distributions resemble a normal distribution
plot(model2$Sol, auto.layout = F)
plot(model2$VCV, auto.layout = F)
# Autocorrelation plots
mcmc_samples2 <- as.mcmc(model2$Sol)
autocorr.plot(mcmc_samples2)

#### Extract Comparisons ####
#Since MCMCglmm models are Bayesian and not directly compatible with emmeans, you need to extract the posterior means and credible intervals manually.

# Extract fixed effects
fixed_effects2 <- model2$Sol

# Extract random effects
random_effects2 <- model2$VCV

# Mean and credible intervals for fixed effects
fixed_means2 <- colMeans(fixed_effects2)
fixed_credible_intervals2 <- t(apply(fixed_effects2, 2, quantile, probs = c(0.025, 0.975)))

# Print results
print(fixed_means2)
print(fixed_credible_intervals2)

# Mean and credible intervals for random effects
random_means2 <- colMeans(random_effects2)
random_credible_intervals2 <- t(apply(random_effects2, 2, quantile, probs = c(0.025, 0.975)))

# Print results
print(random_means2)
print(random_credible_intervals2)

# Calculate variance components for each predictor
var_fixed2 <- apply(fixed_effects2, 2, var)
var_random2 <- apply(random_effects2, 2, var)

# Total variance (fixed + random)
total_variance2 <- var_fixed2 + var_random2

# Marginal R²
marginal_R2.2 <- var_fixed2 / total_variance2

# Conditional R²
conditional_R2.2 <- (var_fixed2 + var_random2) / total_variance2

# Print R² values
# Marginal R2 describes variance explained by fixed factors alone, and conditional R2 describes variance explained by both fixed and random factors
print(marginal_R2.2)
print(conditional_R2.2)

#################
# Get posterior samples for the fixed effects
posterior_samples2 <- model2$Sol

# Define levels for the factors of interest
SymbiontTreatment_levels <- c("C", "D")
Family_levels <- c("F1", "F10", "F2", "F3", "F4", "F6", "F7")
Treatment_levels <- c("31", "35.5", "Ambient")

# Create a new data frame with all combinations of factors
newdata2 <- expand.grid(SymbiontTreatment = SymbiontTreatment_levels,
                       Family = Family_levels,
                       Treatment = Treatment_levels)

# Model matrix for the new data
X_new2 <- model.matrix(~ SymbiontTreatment * Family * Treatment, data = newdata2)
# Subset X_new2 to remove extra interaction terms
X_new2_aligned <- X_new2[, colnames(posterior_samples2), drop = FALSE]

# Calculate posterior predictions for each combination of factor levels
posterior_predictions2 <- X_new2_aligned %*% t(posterior_samples2)

# Summarize the posterior predictions (mean and 95% credible intervals)
marginal_means2 <- apply(posterior_predictions2, 1, function(x) {
  mean_val <- mean(x)
  lower_ci <- quantile(x, 0.025)
  upper_ci <- quantile(x, 0.975)
  return(c(mean = mean_val, lower = lower_ci, upper = upper_ci))
})

# Bind the summary to the original factor levels
result2 <- cbind(newdata2, t(marginal_means2))

# Display the results
print(result2)

# Get the predicted values for PercChange from the model
predictions2 <- predict(model2, type = "response")

# Combine the predictions with the original dataframe
df_with_extremes$PercChange_Cells <- predictions2

# Create a summary dataframe
heatmap_data <- result2 %>%
  group_by(SymbiontTreatment, Family, Treatment) %>%
  summarise(mean_PercChange_Cells = mean(mean, na.rm = TRUE)) %>%
  ungroup()

# Step 1: Ensure the Treatment levels are ordered
heatmap_data <- heatmap_data %>%
  mutate(Treatment = factor(Treatment, levels = c("Ambient", "31", "35.5")))

# Step 2: Create the heatmap with fold change values displayed on each tile
heatmap_plot_cells <- ggplot(heatmap_data, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChange_Cells)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in Symbiont Cell Density",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_cells)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_cells2_PERCENT.png", plot = heatmap_plot_cells, width = 10, height = 8, dpi = 300)

#Square shapes in heat map
heatmap_plot_cells <- ggplot(heatmap_data, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChange_Cells)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
  geom_text(aes(label = round(mean_PercChange_Cells, 2)), color = "black", size = 2) +  # Add fold change values
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in Symbiont Cell Density",
       x = "Family",
       y = "Symbiont Treatment") +
  coord_fixed(ratio = 1)  # Make the tiles more square-shaped by fixing the aspect ratio

# Display the plot
print(heatmap_plot_cells)

# Set the order of the Family factor levels
# DO THIS FOR ALL PLOTS
heatmap_data$Family <- factor(heatmap_data$Family, levels = c("F1", "F2", "F3", "F4", "F6", "F7", "F10"))

# Now create the heatmap again
heatmap_plot_cells3 <- ggplot(heatmap_data, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChange_Cells)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
 # geom_text(aes(label = round(mean_PercChange_Cells, 2)), color = "black", size = 1) +  # Add fold change values
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in Symbiont Cell Density",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_cells3)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_cells2_PERCENT.png", plot = heatmap_plot_cells3, width = 10, height = 8, dpi = 300)

# Change percent to fold change
heatmap_data$fold_change <- 1 + (heatmap_data$mean_PercChange_Cells / 100)

# Create the heatmap with fold change values
heatmap_plot_cells <- ggplot(heatmap_data, aes(x = Family, y = SymbiontTreatment, fill = fold_change)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 1, 
                       name = "Fold Change") +  # Set the midpoint to 1 (neutral fold change)
  facet_wrap(~ Treatment) +
  geom_text(aes(label = round(fold_change, 2)), color = "black", size = 2) +  # Display fold change on tiles
  theme_minimal() +
  labs(title = "Heatmap of Predicted Fold Change in Symbiont Cell Density",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_cells)

### Modeling variables separate for each health metric to get relative contributions ###

mod_cell_treatment <- MCMCglmm(PercChangeCells ~ Treatment, 
                          random = ~ Replicate + Timepoint, 
                          data = df_with_extremes, 
                          family = "gaussian", 
                          prior = prior, 
                          nitt = 50000, 
                          burnin = 10000, 
                          thin = 20)

mod_cell_symbiont <- MCMCglmm(PercChangeCells ~ SymbiontTreatment, 
                         random = ~ Replicate + Timepoint, 
                         data = df_with_extremes, 
                         family = "gaussian", 
                         prior = prior, 
                         nitt = 50000, 
                         burnin = 10000, 
                         thin = 20)

mod_cell_family <- MCMCglmm(PercChangeCells ~ Family, 
                       random = ~ Replicate + Timepoint, 
                       data = df_with_extremes, 
                       family = "gaussian", 
                       prior = prior, 
                       nitt = 50000, 
                       burnin = 10000, 
                       thin = 20)

#Compare models
summary(mod_cell_treatment)    # Check treatment-only model results
summary(mod_cell_symbiont)     # Check symbiont treatment-only model results
summary(mod_cell_family)       # Check family-only model results

# Use the custom pseudoR2 function to get the R² values
r2_full <- pseudoR2.MCMCglmm(model2, data = df_with_extremes)
# Print the results
print(r2_full)

# Use the custom pseudoR2 function to get the R² values
r2_values <- pseudoR2.MCMCglmm(mod_cell_treatment, data = df_with_extremes)
# Print the results
print(r2_values)

# Use the custom pseudoR2 function to get the R² values
r2_values2 <- pseudoR2.MCMCglmm(mod_cell_symbiont, data = df_with_extremes)
# Print the results
print(r2_values2)

# Use the custom pseudoR2 function to get the R² values
r2_values3 <- pseudoR2.MCMCglmm(mod_cell_family, data = df_with_extremes)
# Print the results
print(r2_values3)
```

Run cell density with only survivors

```{r}
# Assuming df_with_extremes is your original dataframe

# Step 1: Identify the vials that survived at time point 22
survived_vials <- unique(df_with_extremes$UniqueID[df_with_extremes$Timepoint == 22 & 
                                                 df_with_extremes$Percent_Survival_atend > 0])

# Step 2: Subset the original dataframe to include only those vials at both time points
df_survived <- df_with_extremes[df_with_extremes$UniqueID %in% survived_vials & 
                                  df_with_extremes$Timepoint %in% c(0, 22), ]

# Print the resulting dataframe
print(df_survived)

# Calculate percent change, adding epsilon to initial values to avoid division by zero
epsilon <- 1e-8  # Add a small value to avoid division by zero
df_survived$PercChangeCells_survived <- ((df_survived$Cellfinal - df_survived$Cellinitial) / 
                                    (df_survived$Cellinitial + epsilon)) * 100

# Define the priors
prior <- list(
  R = list(V = 1, nu = 0.002),  # Prior for residual variance
  G = list(
    G1 = list(V = 1, nu = 5)   # Prior for random effect Timepoint
  )
)

# Fit the model
model_cells_surv <- MCMCglmm(PercChangeCells_survived ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate, 
                  data = df_survived, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval

### Modeling variables separate for each health metric to get relative contributions ###

mod_cell_treatment2 <- MCMCglmm(PercChangeCells_survived ~ Treatment, 
                          random = ~ Replicate, 
                          data = df_survived, 
                          family = "gaussian", 
                          prior = prior, 
                          nitt = 50000, 
                          burnin = 10000, 
                          thin = 20)

mod_cell_symbiont2 <- MCMCglmm(PercChangeCells_survived ~ SymbiontTreatment, 
                         random = ~ Replicate, 
                         data = df_survived, 
                         family = "gaussian", 
                         prior = prior, 
                         nitt = 50000, 
                         burnin = 10000, 
                         thin = 20)

mod_cell_family2 <- MCMCglmm(PercChangeCells_survived ~ Family, 
                       random = ~ Replicate, 
                       data = df_survived, 
                       family = "gaussian", 
                       prior = prior, 
                       nitt = 50000, 
                       burnin = 10000, 
                       thin = 20)

#Compare models
summary(mod_cell_treatment2)    # Check treatment-only model results
summary(mod_cell_symbiont2)     # Check symbiont treatment-only model results
summary(mod_cell_family2)       # Check family-only model results

# Use the custom pseudoR2 function to get the R² values
r2_full2 <- pseudoR2.MCMCglmm(model_cells_surv, data = df_survived)
# Print the results
print(r2_full2)

# Use the custom pseudoR2 function to get the R² values
r2_values <- pseudoR2.MCMCglmm(mod_cell_treatment2, data = df_survived)
# Print the results
print(r2_values)

# Use the custom pseudoR2 function to get the R² values
r2_values2 <- pseudoR2.MCMCglmm(mod_cell_symbiont2, data = df_survived)
# Print the results
print(r2_values2)

# Use the custom pseudoR2 function to get the R² values
r2_values3 <- pseudoR2.MCMCglmm(mod_cell_family2, data = df_survived)
# Print the results
print(r2_values3)

```

FvFm with GLMM --> MCMCglmm 
Fold change in FvFm

```{r}
#fixed effects: symbiont identity, family cross, temperature treatment
#random effects: replicate, timepoint
str(df_with_extremes)

# Calculate percent change, adding epsilon to initial values to avoid division by zero
epsilon <- 1e-8  # Add a small value to avoid division by zero
df_with_extremes$PercChangeFvFm <- ((df_with_extremes$FvFmfinal - df_with_extremes$FvFminitial) / 
                                    (df_with_extremes$FvFminitial + epsilon)) * 100


# Define the priors
prior <- list(
  R = list(V = 1, nu = 0.002),  # Prior for residual variance
  G = list(
    G1 = list(V = 1, nu = 5),  # Prior for random effect Replicate
    G2 = list(V = 1, nu = 5)   # Prior for random effect Timepoint
  )
)

df_with_extremes$PercChangeFvFm[df_with_extremes$PercChangeFvFm == 0] <- 0.0001

# Fit the model
mod.f <- MCMCglmm(PercChangeFvFm ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate + Timepoint, 
                  data = df_with_extremes, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval

#Gelman-Rubin criterion: objective test to determine whether the obtained samples are good
set.seed(1)
m4 <- mclapply(1:4, function(i) {
  MCMCglmm(PercChangeFvFm ~ SymbiontTreatment * Family *
             Treatment, 
             random = ~ Replicate + Timepoint, 
             data = df_with_extremes, 
             family = "gaussian",  # Use gaussian for continuous proportions
             prior = prior,
             nitt = 50000,    # Number of MCMC iterations
             burnin = 10000,  # Burn-in period
             thin = 20)
})

m4 <- lapply(m4, function(m) m$Sol)
m4 <- do.call(mcmc.list, m4)

par(mfrow=c(4,2), mar=c(2,2,1,2))
gelman.plot(m4, auto.layout=F)
gelman.diag(m4)
#close to 1 so we can continue

#plot of the posterior means along with 95% credible intervals
plot.estimates4 <- function(mod.f) {
  # Ensure you have the correct summary
  model_summary4 <- summary(mod.f)
  
  # Extract and filter the relevant parts of the summary
  params4 <- rownames(model_summary4$solutions)
  relevant_params4 <- params4[grep("^(Intercept|SymbiontTreatment|Family|Treatment)", params4)]
  
  # Extract statistics and quantiles
  statistics4 <- model_summary4$solutions[relevant_params4, c("post.mean", "l-95% CI", "u-95% CI")]
  
  # Prepare data for plotting
  stats_df4 <- data.frame(
    parameter = rownames(statistics4),
    mean = statistics2[, "post.mean"],
    lower = statistics2[, "l-95% CI"],
    upper = statistics2[, "u-95% CI"]
  )
  
  # Plot the results
  library(ggplot2)
  ggplot(stats_df4, aes(x = mean, y = parameter)) +
    geom_point(size = 3) +
    geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    labs(title = "Posterior Means and 95% Credible Intervals",
         x = "Posterior Mean",
         y = "Parameter") +
    theme_minimal()
}

#### Check Assumptions ####
# Check trace plots to see if the chains are mixing and if there is convergence
#Check density plots to ensure the posterior distributions resemble a normal distribution
plot(mod.f$Sol, auto.layout = F)
plot(mod.f$VCV, auto.layout = F)
# Autocorrelation plots
mcmc_samples4 <- as.mcmc(mod.f$Sol)
autocorr.plot(mcmc_samples4)

#### Extract Comparisons ####
# Extract fixed effects
fixed_effects4 <- mod.f$Sol

# Extract random effects
random_effects4 <- mod.f$VCV

# Mean and credible intervals for fixed effects
fixed_means4 <- colMeans(fixed_effects4)
fixed_credible_intervals4 <- t(apply(fixed_effects4, 2, quantile, probs = c(0.025, 0.975)))

# Print results
print(fixed_means4)
print(fixed_credible_intervals4)

# Mean and credible intervals for random effects
random_means4 <- colMeans(random_effects4)
random_credible_intervals4 <- t(apply(random_effects4, 2, quantile, probs = c(0.025, 0.975)))

# Print results
print(random_means4)
print(random_credible_intervals4)

# Calculate variance components for each predictor
var_fixed4 <- apply(fixed_effects4, 2, var)
var_random4 <- apply(random_effects4, 2, var)

# Total variance (fixed + random)
total_variance4 <- var_fixed4 + var_random4

# Marginal R²
marginal_R2.4 <- var_fixed4 / total_variance4

# Conditional R²
conditional_R2.4 <- (var_fixed4 + var_random4) / total_variance4

# Print R² values
# Marginal R2 describes variance explained by fixed factors alone, and conditional R2 describes variance explained by both fixed and random factors
print(marginal_R2.4)
print(conditional_R2.4)

#################
# Get posterior samples for the fixed effects
posterior_samples4 <- mod.f$Sol

# Define levels for the factors of interest
SymbiontTreatment_levels <- c("C", "D")
Family_levels <- c("F1", "F10", "F2", "F3", "F4", "F6", "F7")
Treatment_levels <- c("31", "35.5", "Ambient")

# Create a new data frame with all combinations of factors
newdata4 <- expand.grid(SymbiontTreatment = SymbiontTreatment_levels,
                       Family = Family_levels,
                       Treatment = Treatment_levels)

# Model matrix for the new data
X_new4 <- model.matrix(~ SymbiontTreatment * Family * Treatment, data = newdata4)
# Subset X_new2 to remove extra interaction terms
X_new4_aligned <- X_new4[, colnames(posterior_samples4), drop = FALSE]

# Calculate posterior predictions for each combination of factor levels
posterior_predictions4 <- X_new4_aligned %*% t(posterior_samples4)

# Summarize the posterior predictions (mean and 95% credible intervals)
marginal_means4 <- apply(posterior_predictions4, 1, function(x) {
  mean_val <- mean(x)
  lower_ci <- quantile(x, 0.025)
  upper_ci <- quantile(x, 0.975)
  return(c(mean = mean_val, lower = lower_ci, upper = upper_ci))
})

# Bind the summary to the original factor levels
result4 <- cbind(newdata4, t(marginal_means4))

# Display the results
print(result4)

# Get the predicted values for PercChange from the model
predictions4 <- predict(mod.f, type = "response")

# Combine the predictions with the original dataframe
df_with_extremes$PercChangeFvFm <- predictions4

# Create a summary dataframe
heatmap_data4 <- result4 %>%
  group_by(SymbiontTreatment, Family, Treatment) %>%
  summarise(mean_PercChangeFvFm = mean(mean, na.rm = TRUE)) %>%
  ungroup()

# Step 1: Ensure the Treatment levels are ordered
heatmap_data4 <- heatmap_data4 %>%
  mutate(Treatment = factor(Treatment, levels = c("Ambient", "31", "35.5")))

# Step 2: Create the heatmap with fold change values displayed on each tile
heatmap_plot_FvFm <- ggplot(heatmap_data4, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChangeFvFm)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in FvFm",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_FvFm)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_FvFm_PERC.png", plot = heatmap_plot_FvFm, width = 10, height = 8, dpi = 300)

# Set the order of the Family factor levels
heatmap_data4$Family <- factor(heatmap_data4$Family, levels = c("F1", "F2", "F3", "F4", "F6", "F7", "F10"))

# Now create the heatmap again
heatmap_plot_FvFm5 <- ggplot(heatmap_data4, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChangeFvFm)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
 # geom_text(aes(label = round(mean_PercChange_Cells, 2)), color = "black", size = 1) +  # Add fold change values
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in FvFm",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_FvFm5)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_FvFm_PERCENT.png", plot = heatmap_plot_FvFm5, width = 10, height = 8, dpi = 300)

# Change percent to fold change
heatmap_data4$fold_changeFvFm <- 1 + (heatmap_data4$mean_PercChangeFvFm / 100)

# Create the heatmap with fold change values
heatmap_plot_FvFm6 <- ggplot(heatmap_data4, aes(x = Family, y = SymbiontTreatment, fill = fold_changeFvFm)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 1, 
                       name = "Fold Change") +  # Set the midpoint to 1 (neutral fold change)
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "Heatmap of Predicted Fold Change in Fv/Fm",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_FvFm6)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_FvFm_foldchange.png", plot = heatmap_plot_FvFm6, width = 10, height = 8, dpi = 300)

#### Modeling variables separate for each health metric to get relative contributions ###

mod_FvFm_treatment <- MCMCglmm(PercChangeFvFm ~ Treatment, 
                          random = ~ Replicate + Timepoint, 
                          data = df_with_extremes, 
                          family = "gaussian", 
                          prior = prior, 
                          nitt = 50000, 
                          burnin = 10000, 
                          thin = 20)

mod_FvFm_symbiont <- MCMCglmm(PercChangeFvFm ~ SymbiontTreatment, 
                         random = ~ Replicate + Timepoint, 
                         data = df_with_extremes, 
                         family = "gaussian", 
                         prior = prior, 
                         nitt = 50000, 
                         burnin = 10000, 
                         thin = 20)

mod_FvFm_family <- MCMCglmm(PercChangeFvFm ~ Family, 
                       random = ~ Replicate + Timepoint, 
                       data = df_with_extremes, 
                       family = "gaussian", 
                       prior = prior, 
                       nitt = 50000, 
                       burnin = 10000, 
                       thin = 20)

#Compare models
summary(mod_FvFm_treatment)    # Check treatment-only model results
summary(mod_FvFm_symbiont)     # Check symbiont treatment-only model results
summary(mod_FvFm_family)       # Check family-only model results

# Use the custom pseudoR2 function to get the R² values from the full model
r2_full <- pseudoR2.MCMCglmm(mod.f, data = df_with_extremes)
# Print the results
print(r2_full)

# Use the custom pseudoR2 function to get the R² values from Treatment
r2_values.FvFmtreatment <- pseudoR2.MCMCglmm(mod_FvFm_treatment, data = df_with_extremes)
# Print the results
print(r2_values.FvFmtreatment)

# Use the custom pseudoR2 function to get the R² values from SymbiontTreatment
r2_values.FvFmsymb <- pseudoR2.MCMCglmm(mod_FvFm_symbiont, data = df_with_extremes)
# Print the results
print(r2_values.FvFmsymb)

# Use the custom pseudoR2 function to get the R² values from Family
r2_values.FvFmfam <- pseudoR2.MCMCglmm(mod_FvFm_family, data = df_with_extremes)
# Print the results
print(r2_values.FvFmfam)
```

FvFm with only survivors

```{r}
# Calculate percent change, adding epsilon to initial values to avoid division by zero
epsilon <- 1e-8  # Add a small value to avoid division by zero
df_survived$PercChangeFvFm_survived <- ((df_survived$FvFmfinal - df_survived$FvFminitial) / 
                                    (df_survived$FvFminitial + epsilon)) * 100

# Define the priors
prior <- list(
  R = list(V = 1, nu = 0.002),  # Prior for residual variance
  G = list(
    G1 = list(V = 1, nu = 5)   # Prior for random effect Timepoint
  )
)

# Fit the model
mod.f.surv <- MCMCglmm(PercChangeFvFm_survived ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate, 
                  data = df_survived, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval
#### Modeling variables separate for each health metric to get relative contributions ###

mod_FvFm_treatment2 <- MCMCglmm(PercChangeFvFm_survived ~ Treatment, 
                          random = ~ Replicate, 
                          data = df_survived, 
                          family = "gaussian", 
                          prior = prior, 
                          nitt = 50000, 
                          burnin = 10000, 
                          thin = 20)

mod_FvFm_symbiont2 <- MCMCglmm(PercChangeFvFm_survived ~ SymbiontTreatment, 
                         random = ~ Replicate, 
                         data = df_survived, 
                         family = "gaussian", 
                         prior = prior, 
                         nitt = 50000, 
                         burnin = 10000, 
                         thin = 20)

mod_FvFm_family2 <- MCMCglmm(PercChangeFvFm_survived ~ Family, 
                       random = ~ Replicate, 
                       data = df_survived, 
                       family = "gaussian", 
                       prior = prior, 
                       nitt = 50000, 
                       burnin = 10000, 
                       thin = 20)

#Compare models
summary(mod_FvFm_treatment2)    # Check treatment-only model results
summary(mod_FvFm_symbiont2)     # Check symbiont treatment-only model results
summary(mod_FvFm_family2)       # Check family-only model results

# Use the custom pseudoR2 function to get the R² values from the full model
r2_full2 <- pseudoR2.MCMCglmm(mod.f.surv, data = df_survived)
# Print the results
print(r2_full2)

# Use the custom pseudoR2 function to get the R² values from Treatment
r2_values.FvFmtreatment2 <- pseudoR2.MCMCglmm(mod_FvFm_treatment2, data = df_survived)
# Print the results
print(r2_values.FvFmtreatment2)

# Use the custom pseudoR2 function to get the R² values from SymbiontTreatment
r2_values.FvFmsymb2 <- pseudoR2.MCMCglmm(mod_FvFm_symbiont2, data = df_survived)
# Print the results
print(r2_values.FvFmsymb2)

# Use the custom pseudoR2 function to get the R² values from Family
r2_values.FvFmfam2 <- pseudoR2.MCMCglmm(mod_FvFm_family2, data = df_survived)
# Print the results
print(r2_values.FvFmfam2)
```

Larval Size GLMM with MCMCglmm
Fold Change

```{r}
#fixed effects: symbiont identity, family cross, temperature treatment
#random effects: replicate, timepoint
str(df_with_extremes)

# Group by UniqueID and calculate initial and final cell densities
df_with_extremes <- df_with_extremes %>%
  group_by(UniqueID) %>%
  arrange(Timepoint) %>%  # Ensure the dataframe is arranged by Timepoint
  mutate(
    Sizeinitial = first(Area..mm.2.),  # First recorded value of cell density for each UniqueID
    Sizefinal = last(Area..mm.2.)      # Last recorded value of cell density for each UniqueID
  ) %>%
  ungroup()

# Calculate percent change, adding epsilon to initial values to avoid division by zero
epsilon <- 1e-8  # Add a small value to avoid division by zero
df_with_extremes$PercChangeSize <- ((df_with_extremes$Sizefinal - df_with_extremes$Sizeinitial) / 
                                    (df_with_extremes$Sizeinitial + epsilon)) * 100

# Define the priors
prior <- list(
  R = list(V = 1, nu = 0.002),  # Prior for residual variance
  G = list(
    G1 = list(V = 1, nu = 5) # Prior for random effect Timepoint
  )
)

# Fit the model
mod.s <- MCMCglmm(PercChangeSize ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate + Timepoint, 
                  data = df_with_extremes, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval

#Gelman-Rubin criterion: objective test to determine whether the obtained samples are good
set.seed(1)
m5 <- mclapply(1:4, function(i) {
  MCMCglmm(PercChangeSize ~ SymbiontTreatment * Family *
             Treatment, 
             random = ~ Replicate + Timepoint, 
             data = df_with_extremes, 
             family = "gaussian",  # Use gaussian for continuous proportions
             prior = prior,
             nitt = 50000,    # Number of MCMC iterations
             burnin = 10000,  # Burn-in period
             thin = 20)
})

m5 <- lapply(m5, function(m) m$Sol)
m5 <- do.call(mcmc.list, m5)

par(mfrow=c(4,2), mar=c(2,2,1,2))
gelman.plot(m5, auto.layout=F)
gelman.diag(m5)
#close to 1 so we can continue

#plot of the posterior means along with 95% credible intervals
plot.estimates5 <- function(mod.s) {
  # Ensure you have the correct summary
  model_summary5 <- summary(mod.s)
  
  # Extract and filter the relevant parts of the summary
  params5 <- rownames(model_summary5$solutions)
  relevant_params5 <- params5[grep("^(Intercept|SymbiontTreatment|Family|Treatment)", params5)]
  
  # Extract statistics and quantiles
  statistics5 <- model_summary5$solutions[relevant_params5, c("post.mean", "l-95% CI", "u-95% CI")]
  
  # Prepare data for plotting
  stats_df5 <- data.frame(
    parameter = rownames(statistics5),
    mean = statistics2[, "post.mean"],
    lower = statistics2[, "l-95% CI"],
    upper = statistics2[, "u-95% CI"]
  )
  
  # Plot the results
  library(ggplot2)
  ggplot(stats_df5, aes(x = mean, y = parameter)) +
    geom_point(size = 3) +
    geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    labs(title = "Posterior Means and 95% Credible Intervals",
         x = "Posterior Mean",
         y = "Parameter") +
    theme_minimal()
}

#### Check Assumptions ####
# Check trace plots to see if the chains are mixing and if there is convergence
#Check density plots to ensure the posterior distributions resemble a normal distribution
plot(mod.s$Sol, auto.layout = F)
plot(mod.s$VCV, auto.layout = F)
# Autocorrelation plots
mcmc_samples5 <- as.mcmc(mod.s$Sol)
autocorr.plot(mcmc_samples5)

#### Extract Comparisons ####
# Extract fixed effects
fixed_effects5 <- mod.s$Sol

# Extract random effects
random_effects5 <- mod.s$VCV

# Mean and credible intervals for fixed effects
fixed_means5 <- colMeans(fixed_effects5)
fixed_credible_intervals5 <- t(apply(fixed_effects5, 2, quantile, probs = c(0.025, 0.975)))

# Print results
print(fixed_means5)
print(fixed_credible_intervals5)

# Mean and credible intervals for random effects
random_means5 <- colMeans(random_effects5)
random_credible_intervals5 <- t(apply(random_effects5, 2, quantile, probs = c(0.025, 0.975)))

# Print results
print(random_means5)
print(random_credible_intervals5)

# Calculate variance components for each predictor
var_fixed5 <- apply(fixed_effects5, 2, var)
var_random5 <- apply(random_effects5, 2, var)

# Total variance (fixed + random)
total_variance5 <- var_fixed5 + var_random5

# Marginal R²
marginal_R2.5 <- var_fixed5 / total_variance5

# Conditional R²
conditional_R2.5 <- (var_fixed5 + var_random5) / total_variance5

# Print R² values
# Marginal R2 describes variance explained by fixed factors alone, and conditional R2 describes variance explained by both fixed and random factors
print(marginal_R2.5)
print(conditional_R2.5)

#################
# Get posterior samples for the fixed effects
posterior_samples5 <- mod.s$Sol

# Define levels for the factors of interest
SymbiontTreatment_levels <- c("C", "D")
Family_levels <- c("F1", "F10", "F2", "F3", "F4", "F6", "F7")
Treatment_levels <- c("31", "35.5", "Ambient")

# Create a new data frame with all combinations of factors
newdata5 <- expand.grid(SymbiontTreatment = SymbiontTreatment_levels,
                       Family = Family_levels,
                       Treatment = Treatment_levels)

# Model matrix for the new data
X_new5 <- model.matrix(~ SymbiontTreatment * Family * Treatment, data = newdata5)
# Subset X_new2 to remove extra interaction terms
X_new5_aligned <- X_new5[, colnames(posterior_samples5), drop = FALSE]

# Calculate posterior predictions for each combination of factor levels
posterior_predictions5 <- X_new5_aligned %*% t(posterior_samples5)

# Summarize the posterior predictions (mean and 95% credible intervals)
marginal_means5 <- apply(posterior_predictions5, 1, function(x) {
  mean_val <- mean(x)
  lower_ci <- quantile(x, 0.025)
  upper_ci <- quantile(x, 0.975)
  return(c(mean = mean_val, lower = lower_ci, upper = upper_ci))
})

# Bind the summary to the original factor levels
result5 <- cbind(newdata5, t(marginal_means5))

# Display the results
print(result5)

# Get the predicted values for PercChange from the model
predictions5 <- predict(mod.s, type = "response")

# Combine the predictions with the original dataframe
df_with_extremes$PercChangeSize <- predictions5

# Create a summary dataframe
heatmap_data5 <- result5 %>%
  group_by(SymbiontTreatment, Family, Treatment) %>%
  summarise(mean_PercChangeSize = mean(mean, na.rm = TRUE)) %>%
  ungroup()

# Step 1: Ensure the Treatment levels are ordered
heatmap_data5 <- heatmap_data5 %>%
  mutate(Treatment = factor(Treatment, levels = c("Ambient", "31", "35.5")))

# Step 2: Create the heatmap with fold change values displayed on each tile
heatmap_plot_Size <- ggplot(heatmap_data5, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChangeSize)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in Size",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_FvFm)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_Size_PERC.png", plot = heatmap_plot_Size, width = 10, height = 8, dpi = 300)

# Set the order of the Family factor levels
heatmap_data5$Family <- factor(heatmap_data5$Family, levels = c("F1", "F2", "F3", "F4", "F6", "F7", "F10"))

# Now create the heatmap again
heatmap_plot_Size2 <- ggplot(heatmap_data5, aes(x = Family, y = SymbiontTreatment, fill = mean_PercChangeSize)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
                       name = "Mean Percent Change") +
  facet_wrap(~ Treatment) +
 # geom_text(aes(label = round(mean_PercChange_Cells, 2)), color = "black", size = 1) +  # Add fold change values
  theme_minimal() +
  labs(title = "Heatmap of Predicted Change in FvFm",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_Size2)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_FvFm_PERCENT.png", plot = heatmap_plot_Size2, width = 10, height = 8, dpi = 300)

# Change percent to fold change
heatmap_data5$fold_changeSize <- 1 + (heatmap_data5$mean_PercChangeSize / 100)

# Create the heatmap with fold change values
heatmap_plot_Size3 <- ggplot(heatmap_data5, aes(x = Family, y = SymbiontTreatment, fill = fold_changeSize)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 1, 
                       name = "Fold Change") +  # Set the midpoint to 1 (neutral fold change)
  facet_wrap(~ Treatment) +
  theme_minimal() +
  labs(title = "Heatmap of Predicted Fold Change in Larval Size",
       x = "Family",
       y = "Symbiont Treatment")

# Display the plot
print(heatmap_plot_Size3)

ggsave("C:/Users/bellb/OneDrive - James Cook University/Australia/Ningaloo Spawning 2024/Larval Infection Experiment/heatmap_plot_Size_foldchange.png", plot = heatmap_plot_Size3, width = 10, height = 8, dpi = 300)

summary(mod.s)
#Reference levels for summary: SymbiontTreatment = C, Family = F1, and Treatment = 31°C
#The intercept is highly significant (pMCMC < 0.0001), suggesting that the baseline value of PercChangeSize (around 86.22) is far from zero and has strong evidence of being a meaningful effect in the model. This is quite typical when the baseline condition (31C) differs notably from the other levels in the dataset.
#The model shows that the main effect for Treatment 35.5 is significant (pMCMC = 0.037), indicating that the 35.5°C treatment does have a noticeable effect on PercChangeSize compared to the baseline treatment (31°C).
#SymbiontTreatmentD and FamilyF10 are not individually significant, suggesting that on their own, these factors do not have a large impact on the response.

### Modeling variables separate for each health metric to get relative contributions ###

mod_size_treatment <- MCMCglmm(PercChangeSize ~ Treatment, 
                          random = ~ Replicate + Timepoint, 
                          data = df_with_extremes, 
                          family = "gaussian", 
                          prior = prior, 
                          nitt = 50000, 
                          burnin = 10000, 
                          thin = 20)

mod_size_symbiont <- MCMCglmm(PercChangeSize ~ SymbiontTreatment, 
                         random = ~ Replicate + Timepoint, 
                         data = df_with_extremes, 
                         family = "gaussian", 
                         prior = prior, 
                         nitt = 50000, 
                         burnin = 10000, 
                         thin = 20)

mod_size_family <- MCMCglmm(PercChangeSize ~ Family, 
                       random = ~ Replicate + Timepoint, 
                       data = df_with_extremes, 
                       family = "gaussian", 
                       prior = prior, 
                       nitt = 50000, 
                       burnin = 10000, 
                       thin = 20)

#Compare models
summary(mod_size_treatment)    # Check treatment-only model results
summary(mod_size_symbiont)     # Check symbiont treatment-only model results
summary(mod_size_family)       # Check family-only model results

# Use the custom pseudoR2 function to get the R² values from the full model
r2_full <- pseudoR2.MCMCglmm(mod.s, data = df_with_extremes)
# Print the results
print(r2_full)

# Use the custom pseudoR2 function to get the R² values from Treatment
r2_values.sizetreatment <- pseudoR2.MCMCglmm(mod_size_treatment, data = df_with_extremes)
# Print the results
print(r2_values.sizetreatment)

# Use the custom pseudoR2 function to get the R² values from SymbiontTreatment
r2_values.sizesymb <- pseudoR2.MCMCglmm(mod_size_symbiont, data = df_with_extremes)
# Print the results
print(r2_values.sizesymb)

# Use the custom pseudoR2 function to get the R² values from Family
r2_values3 <- pseudoR2.MCMCglmm(mod_size_family, data = df_with_extremes)
# Print the results
print(r2_values3)

#############
# Fit model with Global Intercept Contrast Coding where each treatment (e.g., familial cross × symbiont combination x heat treatment) is compared to the global mean of all treatments
#############
#Make sure variables are factors
df_with_extremes$Treatment <- as.factor(df_with_extremes$Treatment)
df_with_extremes$Family <- as.factor(df_with_extremes$Family)
df_with_extremes$SymbiontTreatment <- as.factor(df_with_extremes$SymbiontTreatment)
# Set sum contrasts for the Treatment, SymbiontTreatment, and Family factors
contrasts(df_with_extremes$Treatment) <- contr.sum(levels(df_with_extremes$Treatment))
contrasts(df_with_extremes$SymbiontTreatment) <- contr.sum(levels(df_with_extremes$SymbiontTreatment))
contrasts(df_with_extremes$Family) <- contr.sum(levels(df_with_extremes$Family))

#original model
mod.s2 <- MCMCglmm(PercChangeSize ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate + Timepoint, 
                  data = df_with_extremes, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval

# Check the contrasts to verify sum contrasts are applied
contrasts(df_with_extremes$Treatment)
contrasts(df_with_extremes$SymbiontTreatment)
contrasts(df_with_extremes$Family)

summary(mod.s2)
```

Run size with only survivors

```{r}
# Assuming df_with_extremes is your original dataframe

# Step 1: Identify the vials that survived at time point 22
survived_vials <- unique(df_with_extremes$UniqueID[df_with_extremes$Timepoint == 22 & 
                                                 df_with_extremes$Percent_Survival_atend > 0])

# Step 2: Subset the original dataframe to include only those vials at both time points
df_survived <- df_with_extremes[df_with_extremes$UniqueID %in% survived_vials & 
                                  df_with_extremes$Timepoint %in% c(0, 22), ]

# Print the resulting dataframe
print(df_survived)

# Calculate percent change, adding epsilon to initial values to avoid division by zero
epsilon <- 1e-8  # Add a small value to avoid division by zero
df_survived$PercChangeSize_survived <- ((df_survived$Sizefinal - df_survived$Sizeinitial) / 
                                    (df_survived$Sizeinitial + epsilon)) * 100

# Define the priors
prior <- list(
  R = list(V = 1, nu = 0.002),  # Prior for residual variance
  G = list(
    G1 = list(V = 1, nu = 5)   # Prior for random effect Timepoint
  )
)

# Fit the model
model_size_surv <- MCMCglmm(PercChangeSize_survived ~ SymbiontTreatment * Family * Treatment, 
                  random = ~ Replicate, 
                  data = df_survived, 
                  family = "gaussian",  # Use gaussian for continuous proportions
                  prior = prior,
                  nitt = 50000,    # Number of MCMC iterations
                  burnin = 10000,  # Burn-in period
                  thin = 20)       # Thinning interval

### Modeling variables separate for each health metric to get relative contributions ###

mod_size_treatment2 <- MCMCglmm(PercChangeSize_survived ~ Treatment, 
                          random = ~ Replicate, 
                          data = df_survived, 
                          family = "gaussian", 
                          prior = prior, 
                          nitt = 50000, 
                          burnin = 10000, 
                          thin = 20)

mod_size_symbiont2 <- MCMCglmm(PercChangeSize_survived ~ SymbiontTreatment, 
                         random = ~ Replicate, 
                         data = df_survived, 
                         family = "gaussian", 
                         prior = prior, 
                         nitt = 50000, 
                         burnin = 10000, 
                         thin = 20)

mod_size_family2 <- MCMCglmm(PercChangeSize_survived ~ Family, 
                       random = ~ Replicate, 
                       data = df_survived, 
                       family = "gaussian", 
                       prior = prior, 
                       nitt = 50000, 
                       burnin = 10000, 
                       thin = 20)

#Compare models
summary(mod_size_treatment2)    # Check treatment-only model results
summary(mod_size_symbiont2)     # Check symbiont treatment-only model results
summary(mod_size_family2)       # Check family-only model results

# Use the custom pseudoR2 function to get the R² values
r2_full2 <- pseudoR2.MCMCglmm(model_size_surv, data = df_survived)
# Print the results
print(r2_full2)

# Use the custom pseudoR2 function to get the R² values for treatment only
r2_values4 <- pseudoR2.MCMCglmm(mod_size_treatment2, data = df_survived)
# Print the results
print(r2_values4)

# Use the custom pseudoR2 function to get the R² values for symbiont only
r2_values5 <- pseudoR2.MCMCglmm(mod_size_symbiont2, data = df_survived)
# Print the results
print(r2_values5)

# Use the custom pseudoR2 function to get the R² values
r2_values6 <- pseudoR2.MCMCglmm(mod_size_family2, data = df_survived)
# Print the results
print(r2_values6)

```

